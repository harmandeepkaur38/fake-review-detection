{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lenovo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "CNN on kaggle fake news dataset \n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "def load_kagglefakenews():\n",
    "  \n",
    "    df = pd.read_csv('Kaggle_FakeNews/train.csv', nrows=10000, encoding='utf8')\n",
    "    train_data = df['text'].values.tolist() \n",
    "    train_labels = df['label'].values.tolist() \n",
    "\n",
    "\n",
    "    combo = list(zip(train_data, train_labels))\n",
    "    random.shuffle(combo)\n",
    "    train_data, train_labels = zip(*combo)\n",
    "    del df\n",
    "\n",
    "    return np.asarray(train_data).tolist(), np.asarray(train_labels).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = load_kagglefakenews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "\n",
    "MAX_NB_WORDS=50000 #dictionary size\n",
    "MAX_SEQUENCE_LENGTH=1500 #max word length of each individual article\n",
    "EMBEDDING_DIM=300 #dimensionality of the embedding vector (50, 100, 200, 300)\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~')\n",
    "\n",
    "def tokenize_trainingdata(texts, labels):\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    pickle.dump(tokenizer, open('Models/tokenizer.p', 'wb'))\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    labels = to_categorical(labels, num_classes=len(set(labels)))\n",
    "\n",
    "    return data, labels, word_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165537 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "X, Y, word_index = tokenize_trainingdata(train_data, train_labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data (90% train, 5% test, 5% validation)\n",
    "train_data = X[:int(len(X)*0.9)]\n",
    "train_labels = Y[:int(len(X)*0.9)]\n",
    "test_data = X[int(len(X)*0.9):int(len(X)*0.95)]\n",
    "test_labels = Y[int(len(X)*0.9):int(len(X)*0.95)]\n",
    "valid_data = X[int(len(X)*0.95):]\n",
    "valid_labels = Y[int(len(X)*0.95):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings(word_index, embeddingsfile='wordEmbeddings/glove.6B.%id.txt' %EMBEDDING_DIM):\n",
    "    embeddings_index = {}\n",
    "    f = open(embeddingsfile, 'r', encoding='utf8')\n",
    "    for line in f:\n",
    "        \n",
    "        values = line.split(' ') \n",
    "        word = values[0] \n",
    "        coefs = np.asarray(values[1:], dtype='float32') \n",
    "        embeddings_index[word] = coefs \n",
    "    f.close()\n",
    "\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False)\n",
    "    return embedding_layer\n",
    "    \n",
    "\n",
    "embedding_layer = load_embeddings(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, Model, Input\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Dense, GlobalAveragePooling1D, Dropout, LSTM, CuDNNLSTM, RNN, SimpleRNN, Conv2D, GlobalMaxPooling1D\n",
    "from keras import callbacks\n",
    "\n",
    "def baseline_model(sequence_input, embedded_sequences, classes=2):\n",
    "    x = Conv1D(64, 5, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(128, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(256, 2, activation='relu')(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    preds = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lenovo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1500, 300)         49661400  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1496, 64)          96064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 299, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 297, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 59, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 58, 256)           65792     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              526336    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 51,424,410\n",
      "Trainable params: 1,763,010\n",
      "Non-trainable params: 49,661,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/lenovo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 9000 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "9000/9000 [==============================] - 56s 6ms/step - loss: 0.4627 - acc: 0.7639 - val_loss: 0.2819 - val_acc: 0.8860\n",
      "Epoch 2/25\n",
      "9000/9000 [==============================] - 63s 7ms/step - loss: 0.1664 - acc: 0.9390 - val_loss: 0.1625 - val_acc: 0.9340\n",
      "Epoch 3/25\n",
      "9000/9000 [==============================] - 70s 8ms/step - loss: 0.0775 - acc: 0.9746 - val_loss: 0.1257 - val_acc: 0.9420\n",
      "Epoch 4/25\n",
      "9000/9000 [==============================] - 73s 8ms/step - loss: 0.0436 - acc: 0.9854 - val_loss: 0.1507 - val_acc: 0.9520\n",
      "Epoch 5/25\n",
      "9000/9000 [==============================] - 73s 8ms/step - loss: 0.0322 - acc: 0.9897 - val_loss: 0.1309 - val_acc: 0.9560\n",
      "Epoch 6/25\n",
      "9000/9000 [==============================] - 54s 6ms/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.1492 - val_acc: 0.9540\n",
      "Epoch 7/25\n",
      "9000/9000 [==============================] - 52s 6ms/step - loss: 0.0110 - acc: 0.9960 - val_loss: 0.1498 - val_acc: 0.9620\n",
      "Epoch 8/25\n",
      "9000/9000 [==============================] - 53s 6ms/step - loss: 0.0108 - acc: 0.9950 - val_loss: 0.1277 - val_acc: 0.9580\n",
      "Epoch 9/25\n",
      "9000/9000 [==============================] - 54s 6ms/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.1457 - val_acc: 0.9660\n",
      "Epoch 10/25\n",
      "9000/9000 [==============================] - 57s 6ms/step - loss: 6.0727e-04 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9620\n",
      "Epoch 11/25\n",
      "9000/9000 [==============================] - 54s 6ms/step - loss: 1.4962e-04 - acc: 1.0000 - val_loss: 0.1957 - val_acc: 0.9600\n",
      "Epoch 12/25\n",
      "9000/9000 [==============================] - 62s 7ms/step - loss: 1.1832e-04 - acc: 1.0000 - val_loss: 0.1972 - val_acc: 0.9600\n",
      "Epoch 13/25\n",
      "9000/9000 [==============================] - 57s 6ms/step - loss: 6.7764e-05 - acc: 1.0000 - val_loss: 0.1957 - val_acc: 0.9640\n",
      "Epoch 14/25\n",
      "9000/9000 [==============================] - 56s 6ms/step - loss: 5.5852e-05 - acc: 1.0000 - val_loss: 0.2059 - val_acc: 0.9640\n",
      "Epoch 15/25\n",
      "9000/9000 [==============================] - 53s 6ms/step - loss: 4.7755e-05 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9640\n",
      "Epoch 16/25\n",
      "9000/9000 [==============================] - 57s 6ms/step - loss: 4.2416e-05 - acc: 1.0000 - val_loss: 0.2514 - val_acc: 0.9600\n",
      "Epoch 17/25\n",
      "9000/9000 [==============================] - 59s 7ms/step - loss: 4.4877e-05 - acc: 1.0000 - val_loss: 0.2381 - val_acc: 0.9600\n",
      "Epoch 18/25\n",
      "9000/9000 [==============================] - 63s 7ms/step - loss: 1.9186e-05 - acc: 1.0000 - val_loss: 0.2274 - val_acc: 0.9660\n",
      "Epoch 19/25\n",
      "9000/9000 [==============================] - 63s 7ms/step - loss: 1.7131e-05 - acc: 1.0000 - val_loss: 0.2361 - val_acc: 0.9660\n",
      "Epoch 20/25\n",
      "9000/9000 [==============================] - 85s 9ms/step - loss: 1.1431e-05 - acc: 1.0000 - val_loss: 0.2426 - val_acc: 0.9640\n",
      "Epoch 21/25\n",
      "9000/9000 [==============================] - 54s 6ms/step - loss: 1.2408e-05 - acc: 1.0000 - val_loss: 0.2364 - val_acc: 0.9660\n",
      "Epoch 22/25\n",
      "9000/9000 [==============================] - 57s 6ms/step - loss: 7.9552e-06 - acc: 1.0000 - val_loss: 0.2514 - val_acc: 0.9660\n",
      "Epoch 23/25\n",
      "9000/9000 [==============================] - 61s 7ms/step - loss: 9.6526e-06 - acc: 1.0000 - val_loss: 0.2414 - val_acc: 0.9660\n",
      "Epoch 24/25\n",
      "9000/9000 [==============================] - 94s 10ms/step - loss: 6.2345e-06 - acc: 1.0000 - val_loss: 0.2589 - val_acc: 0.9660\n",
      "Epoch 25/25\n",
      "9000/9000 [==============================] - 112s 12ms/step - loss: 8.6693e-06 - acc: 1.0000 - val_loss: 0.2536 - val_acc: 0.9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe311553150>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MAX_SEQUENCE_LENGTH=1500\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "model = baseline_model(sequence_input, embedded_sequences, classes=2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adamax',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"cnn_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8af6246a03e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lenovo/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lenovo/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    509\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lenovo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat_probs = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99957442e-01 4.25153303e-05]\n",
      " [3.17469040e-27 1.00000000e+00]\n",
      " [1.00000000e+00 2.60201692e-16]\n",
      " [7.81328424e-09 1.00000000e+00]\n",
      " [9.99600351e-01 3.99614801e-04]\n",
      " [1.00000000e+00 5.78775495e-16]\n",
      " [1.96648343e-03 9.98033464e-01]\n",
      " [7.29203178e-03 9.92708027e-01]\n",
      " [7.48082152e-11 1.00000000e+00]\n",
      " [3.50618046e-09 1.00000000e+00]\n",
      " [1.00000000e+00 4.27612390e-11]\n",
      " [1.00000000e+00 8.61497441e-18]\n",
      " [1.00000000e+00 5.54088153e-09]\n",
      " [1.00000000e+00 3.35797726e-21]\n",
      " [9.99977231e-01 2.27407781e-05]\n",
      " [1.00000000e+00 5.59039098e-17]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.99963045e-01 3.70091802e-05]\n",
      " [1.00000000e+00 2.00484974e-13]\n",
      " [1.00000000e+00 1.49589463e-09]\n",
      " [1.00000000e+00 2.56968030e-10]\n",
      " [1.17639262e-30 1.00000000e+00]\n",
      " [1.00000000e+00 1.18400449e-17]\n",
      " [1.33806025e-05 9.99986649e-01]\n",
      " [4.25960976e-36 1.00000000e+00]\n",
      " [1.63147228e-15 1.00000000e+00]\n",
      " [1.64938660e-06 9.99998331e-01]\n",
      " [4.70599037e-14 1.00000000e+00]\n",
      " [1.00000000e+00 1.17740399e-13]\n",
      " [1.00000000e+00 5.18595442e-08]\n",
      " [7.17579587e-13 1.00000000e+00]\n",
      " [8.08590001e-12 1.00000000e+00]\n",
      " [9.54356901e-14 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 3.72397665e-16]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.02199432e-04 9.99897838e-01]\n",
      " [9.99999881e-01 1.16993952e-07]\n",
      " [1.00000000e+00 2.34639617e-11]\n",
      " [1.00000000e+00 2.19203021e-15]\n",
      " [6.97768510e-10 1.00000000e+00]\n",
      " [7.66290486e-01 2.33709544e-01]\n",
      " [9.99997377e-01 2.62628555e-06]\n",
      " [1.00000000e+00 3.34335498e-21]\n",
      " [1.00000000e+00 1.86794495e-13]\n",
      " [1.00000000e+00 1.14194842e-23]\n",
      " [9.99999881e-01 1.75544500e-07]\n",
      " [1.00000000e+00 1.36649840e-16]\n",
      " [9.99993920e-01 6.11529686e-06]\n",
      " [7.19484096e-18 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 9.04758971e-17]\n",
      " [1.00000000e+00 4.56938045e-17]\n",
      " [1.00000000e+00 4.91268626e-09]\n",
      " [9.76308704e-18 1.00000000e+00]\n",
      " [1.00000000e+00 4.89001131e-11]\n",
      " [2.63845514e-08 1.00000000e+00]\n",
      " [5.80748392e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.18637547e-16]\n",
      " [5.43747256e-21 1.00000000e+00]\n",
      " [1.00000000e+00 1.42827647e-22]\n",
      " [1.00000000e+00 4.71016092e-20]\n",
      " [8.51383254e-13 1.00000000e+00]\n",
      " [1.00000000e+00 2.09286144e-09]\n",
      " [9.99938726e-01 6.12612275e-05]\n",
      " [1.08039171e-23 1.00000000e+00]\n",
      " [1.00000000e+00 3.02322458e-21]\n",
      " [1.00000000e+00 4.01718658e-10]\n",
      " [9.99981046e-01 1.89056645e-05]\n",
      " [4.16459888e-01 5.83540142e-01]\n",
      " [7.45461106e-01 2.54538924e-01]\n",
      " [1.01299247e-06 9.99999046e-01]\n",
      " [2.76822969e-29 1.00000000e+00]\n",
      " [1.00000000e+00 4.19034984e-09]\n",
      " [1.94857108e-09 1.00000000e+00]\n",
      " [1.00000000e+00 5.59565960e-25]\n",
      " [6.21477000e-07 9.99999404e-01]\n",
      " [1.00000000e+00 6.60397962e-15]\n",
      " [4.39617696e-16 1.00000000e+00]\n",
      " [9.99999881e-01 1.57910591e-07]\n",
      " [9.99994278e-01 5.70727661e-06]\n",
      " [3.96033693e-06 9.99996066e-01]\n",
      " [1.00000000e+00 6.98388266e-12]\n",
      " [1.39305029e-14 1.00000000e+00]\n",
      " [1.00000000e+00 2.54660083e-18]\n",
      " [2.86368280e-08 1.00000000e+00]\n",
      " [1.00000000e+00 1.68757838e-11]\n",
      " [5.75564897e-25 1.00000000e+00]\n",
      " [9.99987602e-01 1.24431635e-05]\n",
      " [1.97530201e-15 1.00000000e+00]\n",
      " [1.53789450e-26 1.00000000e+00]\n",
      " [1.48584229e-13 1.00000000e+00]\n",
      " [5.21169170e-07 9.99999523e-01]\n",
      " [1.00000000e+00 1.37439905e-14]\n",
      " [9.99993086e-01 6.96919187e-06]\n",
      " [7.64960259e-28 1.00000000e+00]\n",
      " [7.76897311e-01 2.23102704e-01]\n",
      " [1.26512443e-26 1.00000000e+00]\n",
      " [1.56251056e-13 1.00000000e+00]\n",
      " [9.99999881e-01 9.95527856e-08]\n",
      " [1.21220686e-10 1.00000000e+00]\n",
      " [5.11056781e-01 4.88943189e-01]\n",
      " [1.00000000e+00 6.21012813e-26]\n",
      " [6.44264801e-05 9.99935627e-01]\n",
      " [1.55129776e-09 1.00000000e+00]\n",
      " [2.18821503e-20 1.00000000e+00]\n",
      " [1.27088447e-06 9.99998689e-01]\n",
      " [1.00000000e+00 2.41607220e-11]\n",
      " [1.00000000e+00 4.16204315e-08]\n",
      " [7.89882493e-10 1.00000000e+00]\n",
      " [8.49754371e-17 1.00000000e+00]\n",
      " [9.99972701e-01 2.73190162e-05]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.94696259e-01 5.30372048e-03]\n",
      " [8.53813350e-01 1.46186590e-01]\n",
      " [5.19200403e-04 9.99480784e-01]\n",
      " [1.00000000e+00 2.42124452e-29]\n",
      " [1.00000000e+00 8.22144397e-09]\n",
      " [2.47785334e-11 1.00000000e+00]\n",
      " [2.93956731e-07 9.99999762e-01]\n",
      " [1.12349250e-33 1.00000000e+00]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.99999642e-01 3.83487958e-07]\n",
      " [1.00000000e+00 5.58040454e-11]\n",
      " [1.99951593e-08 1.00000000e+00]\n",
      " [3.70827919e-26 1.00000000e+00]\n",
      " [1.00000000e+00 8.64959637e-15]\n",
      " [9.23283935e-01 7.67160505e-02]\n",
      " [1.00000000e+00 1.00375562e-10]\n",
      " [6.61744714e-01 3.38255346e-01]\n",
      " [2.47530024e-13 1.00000000e+00]\n",
      " [1.54355327e-20 1.00000000e+00]\n",
      " [1.09991902e-06 9.99998927e-01]\n",
      " [1.00000000e+00 3.29523904e-14]\n",
      " [4.31728187e-14 1.00000000e+00]\n",
      " [8.77796457e-31 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [2.53699913e-20 1.00000000e+00]\n",
      " [1.00000000e+00 3.77668480e-10]\n",
      " [9.99891520e-01 1.08412838e-04]\n",
      " [9.56347198e-13 1.00000000e+00]\n",
      " [1.76524767e-03 9.98234749e-01]\n",
      " [3.75224090e-07 9.99999642e-01]\n",
      " [1.03050013e-08 1.00000000e+00]\n",
      " [1.00000000e+00 2.02799000e-14]\n",
      " [1.83463546e-15 1.00000000e+00]\n",
      " [4.59297040e-18 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.61635354e-12 1.00000000e+00]\n",
      " [1.00000000e+00 2.18449020e-17]\n",
      " [1.23682002e-11 1.00000000e+00]\n",
      " [9.99987721e-01 1.23314703e-05]\n",
      " [9.99999762e-01 2.90134153e-07]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 2.79732780e-13]\n",
      " [1.48430521e-08 1.00000000e+00]\n",
      " [9.99997377e-01 2.56928661e-06]\n",
      " [9.86885667e-01 1.31143387e-02]\n",
      " [1.74879958e-07 9.99999881e-01]\n",
      " [9.99999881e-01 1.23516514e-07]\n",
      " [1.00000000e+00 1.42564988e-11]\n",
      " [4.14523612e-07 9.99999642e-01]\n",
      " [1.00000000e+00 4.82491685e-11]\n",
      " [9.11885814e-04 9.99088168e-01]\n",
      " [1.00000000e+00 1.93609393e-20]\n",
      " [1.00000000e+00 1.19847110e-09]\n",
      " [1.00000000e+00 9.88242821e-11]\n",
      " [9.99996662e-01 3.38682139e-06]\n",
      " [1.00000000e+00 7.13323159e-21]\n",
      " [1.00000000e+00 6.60047374e-24]\n",
      " [1.00000000e+00 2.06350955e-13]\n",
      " [1.00000000e+00 6.82759079e-13]\n",
      " [9.99521136e-01 4.78847185e-04]\n",
      " [1.00000000e+00 1.14531428e-19]\n",
      " [1.00000000e+00 2.57448159e-30]\n",
      " [9.99999404e-01 6.26545500e-07]\n",
      " [1.00000000e+00 1.18623292e-10]\n",
      " [3.60486661e-06 9.99996424e-01]\n",
      " [1.00000000e+00 2.62685091e-08]\n",
      " [1.00000000e+00 4.64387854e-36]\n",
      " [3.56677437e-19 1.00000000e+00]\n",
      " [1.00000000e+00 9.42912345e-11]\n",
      " [5.11903562e-13 1.00000000e+00]\n",
      " [3.08821877e-14 1.00000000e+00]\n",
      " [9.97595608e-01 2.40442995e-03]\n",
      " [4.52838702e-20 1.00000000e+00]\n",
      " [1.06829404e-07 9.99999881e-01]\n",
      " [1.00000000e+00 6.76757617e-24]\n",
      " [4.69667279e-18 1.00000000e+00]\n",
      " [1.00000000e+00 4.37183831e-11]\n",
      " [7.15826285e-34 1.00000000e+00]\n",
      " [1.00000000e+00 1.54689239e-09]\n",
      " [1.00000000e+00 4.79228657e-10]\n",
      " [4.24124486e-11 1.00000000e+00]\n",
      " [9.92670417e-01 7.32952636e-03]\n",
      " [4.63229144e-09 1.00000000e+00]\n",
      " [1.00000000e+00 4.35927743e-28]\n",
      " [1.94860350e-10 1.00000000e+00]\n",
      " [4.04831897e-12 1.00000000e+00]\n",
      " [2.00824925e-12 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.99993801e-01 6.22453763e-06]\n",
      " [1.00000000e+00 3.50694574e-15]\n",
      " [1.72969244e-14 1.00000000e+00]\n",
      " [5.46516565e-12 1.00000000e+00]\n",
      " [9.99999762e-01 2.79610902e-07]\n",
      " [1.00000000e+00 1.43209912e-17]\n",
      " [1.00000000e+00 4.22498792e-09]\n",
      " [1.55450673e-15 1.00000000e+00]\n",
      " [1.00000000e+00 5.57855791e-13]\n",
      " [1.87035082e-10 1.00000000e+00]\n",
      " [8.03966105e-01 1.96033865e-01]\n",
      " [2.64662035e-08 1.00000000e+00]\n",
      " [4.87225633e-15 1.00000000e+00]\n",
      " [5.26388782e-22 1.00000000e+00]\n",
      " [4.77557065e-25 1.00000000e+00]\n",
      " [6.31099238e-06 9.99993682e-01]\n",
      " [1.00000000e+00 2.10908345e-16]\n",
      " [1.00000000e+00 3.97216228e-15]\n",
      " [9.84785704e-16 1.00000000e+00]\n",
      " [6.91217124e-01 3.08782876e-01]\n",
      " [4.27196585e-02 9.57280278e-01]\n",
      " [2.39667315e-07 9.99999762e-01]\n",
      " [1.00000000e+00 1.57018665e-08]\n",
      " [1.00000000e+00 4.67555309e-14]\n",
      " [6.34141910e-16 1.00000000e+00]\n",
      " [5.02006660e-19 1.00000000e+00]\n",
      " [1.00000000e+00 5.28337596e-09]\n",
      " [7.76210736e-18 1.00000000e+00]\n",
      " [1.00000000e+00 6.91881856e-17]\n",
      " [3.96033693e-06 9.99996066e-01]\n",
      " [1.34178683e-01 8.65821362e-01]\n",
      " [6.05530575e-28 1.00000000e+00]\n",
      " [1.00000000e+00 1.12307572e-20]\n",
      " [9.54157673e-12 1.00000000e+00]\n",
      " [2.36314106e-25 1.00000000e+00]\n",
      " [6.74206599e-24 1.00000000e+00]\n",
      " [1.00000000e+00 2.99513459e-14]\n",
      " [1.00000000e+00 6.61302452e-24]\n",
      " [2.94039547e-16 1.00000000e+00]\n",
      " [9.99999523e-01 5.31331239e-07]\n",
      " [7.28625060e-14 1.00000000e+00]\n",
      " [2.78187712e-35 1.00000000e+00]\n",
      " [3.96033693e-06 9.99996066e-01]\n",
      " [9.04859273e-24 1.00000000e+00]\n",
      " [8.52826388e-17 1.00000000e+00]\n",
      " [1.00000000e+00 1.50296340e-14]\n",
      " [2.78921449e-04 9.99721110e-01]\n",
      " [4.95049626e-01 5.04950345e-01]\n",
      " [7.58052821e-08 9.99999881e-01]\n",
      " [6.97189702e-14 1.00000000e+00]\n",
      " [9.99997735e-01 2.21662685e-06]\n",
      " [1.00000000e+00 5.91170721e-13]\n",
      " [1.00000000e+00 7.73297459e-16]\n",
      " [1.00000000e+00 2.29448573e-16]\n",
      " [1.00000000e+00 4.55036346e-19]\n",
      " [8.02898499e-21 1.00000000e+00]\n",
      " [4.74008094e-13 1.00000000e+00]\n",
      " [1.00000000e+00 1.12663577e-15]\n",
      " [6.90565938e-10 1.00000000e+00]\n",
      " [5.15911522e-17 1.00000000e+00]\n",
      " [1.30872003e-32 1.00000000e+00]\n",
      " [9.99753773e-01 2.46263371e-04]\n",
      " [1.00000000e+00 3.41685357e-18]\n",
      " [1.74705729e-05 9.99982476e-01]\n",
      " [5.44485413e-02 9.45551455e-01]\n",
      " [7.48256796e-17 1.00000000e+00]\n",
      " [1.00000000e+00 4.11799483e-09]\n",
      " [4.83815224e-14 1.00000000e+00]\n",
      " [1.07434562e-24 1.00000000e+00]\n",
      " [1.00000000e+00 2.53776822e-09]\n",
      " [2.51543429e-06 9.99997497e-01]\n",
      " [9.99999404e-01 5.41201302e-07]\n",
      " [1.00000000e+00 2.98005864e-09]\n",
      " [1.00000000e+00 3.26453016e-17]\n",
      " [9.99964237e-01 3.58084362e-05]\n",
      " [7.59828733e-09 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [4.67276365e-01 5.32723606e-01]\n",
      " [1.00000000e+00 2.87188994e-14]\n",
      " [3.96033693e-06 9.99996066e-01]\n",
      " [1.00000000e+00 1.49548292e-14]\n",
      " [8.47100018e-05 9.99915242e-01]\n",
      " [1.00000000e+00 4.19348609e-08]\n",
      " [4.42871110e-17 1.00000000e+00]\n",
      " [1.00000000e+00 4.77799666e-09]\n",
      " [1.00000000e+00 1.08412882e-14]\n",
      " [1.00000000e+00 1.00187702e-18]\n",
      " [1.69279313e-20 1.00000000e+00]\n",
      " [1.00000000e+00 5.48904744e-08]\n",
      " [2.33724654e-06 9.99997616e-01]\n",
      " [9.99971509e-01 2.84358175e-05]\n",
      " [9.99948859e-01 5.11383732e-05]\n",
      " [1.00000000e+00 3.59611292e-08]\n",
      " [1.00000000e+00 1.10298558e-11]\n",
      " [4.62537370e-11 1.00000000e+00]\n",
      " [1.00000000e+00 2.19436954e-18]\n",
      " [9.99999523e-01 5.02373041e-07]\n",
      " [9.99996543e-01 3.49384368e-06]\n",
      " [1.26092056e-15 1.00000000e+00]\n",
      " [1.35145128e-28 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [7.75134956e-11 1.00000000e+00]\n",
      " [1.00000000e+00 4.76747412e-16]\n",
      " [1.10145031e-12 1.00000000e+00]\n",
      " [1.00000000e+00 7.07703118e-10]\n",
      " [1.00000000e+00 2.69863342e-13]\n",
      " [2.91104675e-06 9.99997139e-01]\n",
      " [1.33152956e-13 1.00000000e+00]\n",
      " [9.99985218e-01 1.47998007e-05]\n",
      " [6.31110950e-08 9.99999881e-01]\n",
      " [2.79615957e-13 1.00000000e+00]\n",
      " [1.00000000e+00 6.03401802e-22]\n",
      " [1.00000000e+00 5.16066888e-25]\n",
      " [1.00000000e+00 1.71630314e-11]\n",
      " [6.90463764e-07 9.99999285e-01]\n",
      " [1.00000000e+00 2.68079987e-21]\n",
      " [1.61669086e-04 9.99838352e-01]\n",
      " [1.00000000e+00 4.26955076e-28]\n",
      " [1.00000000e+00 7.03814042e-14]\n",
      " [1.00000000e+00 1.23609672e-25]\n",
      " [9.99999881e-01 1.67126132e-07]\n",
      " [6.42030129e-18 1.00000000e+00]\n",
      " [1.00000000e+00 1.31694989e-22]\n",
      " [8.89816603e-21 1.00000000e+00]\n",
      " [2.04656823e-21 1.00000000e+00]\n",
      " [1.00000000e+00 5.00814291e-22]\n",
      " [1.13943160e-11 1.00000000e+00]\n",
      " [1.00109054e-17 1.00000000e+00]\n",
      " [6.61281424e-19 1.00000000e+00]\n",
      " [1.00000000e+00 2.01372556e-13]\n",
      " [9.99999881e-01 9.96667779e-08]\n",
      " [1.00000000e+00 1.77406667e-19]\n",
      " [1.00000000e+00 7.16204118e-09]\n",
      " [9.98173356e-01 1.82658702e-03]\n",
      " [9.99994874e-01 5.13114901e-06]\n",
      " [6.59642967e-14 1.00000000e+00]\n",
      " [1.26310284e-09 1.00000000e+00]\n",
      " [1.00000000e+00 1.00705347e-11]\n",
      " [9.99963760e-01 3.62861538e-05]\n",
      " [1.00000000e+00 7.10611570e-09]\n",
      " [1.00000000e+00 9.73242021e-16]\n",
      " [1.45604445e-10 1.00000000e+00]\n",
      " [4.00831972e-08 1.00000000e+00]\n",
      " [4.21545167e-07 9.99999523e-01]\n",
      " [1.00000000e+00 4.56527338e-15]\n",
      " [1.00000000e+00 1.13764829e-08]\n",
      " [1.00000000e+00 1.84185925e-14]\n",
      " [9.99999404e-01 5.38685356e-07]\n",
      " [1.00000000e+00 7.19753095e-18]\n",
      " [9.99159694e-01 8.40323861e-04]\n",
      " [9.99994159e-01 5.89179217e-06]\n",
      " [8.30687461e-17 1.00000000e+00]\n",
      " [1.00000000e+00 1.07387033e-09]\n",
      " [1.00000000e+00 5.13785466e-21]\n",
      " [6.20876108e-06 9.99993801e-01]\n",
      " [1.88662496e-04 9.99811351e-01]\n",
      " [1.81450466e-10 1.00000000e+00]\n",
      " [4.41785128e-29 1.00000000e+00]\n",
      " [6.84709722e-14 1.00000000e+00]\n",
      " [1.00000000e+00 2.89011731e-10]\n",
      " [1.00000000e+00 1.03868549e-08]\n",
      " [1.32115239e-13 1.00000000e+00]\n",
      " [9.93699670e-01 6.30026124e-03]\n",
      " [1.10286132e-01 8.89713883e-01]\n",
      " [1.50848422e-07 9.99999881e-01]\n",
      " [3.31074509e-24 1.00000000e+00]\n",
      " [1.80491148e-22 1.00000000e+00]\n",
      " [3.06893011e-10 1.00000000e+00]\n",
      " [9.99999404e-01 5.51397875e-07]\n",
      " [9.99990821e-01 9.12217092e-06]\n",
      " [9.65086429e-08 9.99999881e-01]\n",
      " [7.87182671e-06 9.99992132e-01]\n",
      " [2.23290783e-07 9.99999762e-01]\n",
      " [9.99999881e-01 6.58666792e-08]\n",
      " [9.99998808e-01 1.17915306e-06]\n",
      " [1.05303787e-12 1.00000000e+00]\n",
      " [1.00000000e+00 1.67208629e-08]\n",
      " [9.99999404e-01 6.24738220e-07]\n",
      " [1.94581650e-19 1.00000000e+00]\n",
      " [1.24966593e-10 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.08829168e-09 1.00000000e+00]\n",
      " [9.34062002e-27 1.00000000e+00]\n",
      " [1.69062436e-01 8.30937564e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.96241212e-01 3.75878345e-03]\n",
      " [9.99961019e-01 3.90269051e-05]\n",
      " [6.63864727e-11 1.00000000e+00]\n",
      " [2.83021730e-08 1.00000000e+00]\n",
      " [8.99990857e-01 1.00009091e-01]\n",
      " [1.00000000e+00 1.02809193e-18]\n",
      " [1.03593436e-06 9.99998927e-01]\n",
      " [1.00000000e+00 9.75373948e-19]\n",
      " [1.89580023e-02 9.81042027e-01]\n",
      " [9.99999046e-01 9.08905179e-07]\n",
      " [1.00000000e+00 5.12259512e-19]\n",
      " [5.44316328e-12 1.00000000e+00]\n",
      " [4.06673416e-06 9.99995947e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 1.44045781e-20]\n",
      " [1.00000000e+00 7.84615040e-10]\n",
      " [2.27464852e-03 9.97725308e-01]\n",
      " [1.47527271e-06 9.99998569e-01]\n",
      " [1.00000000e+00 7.26691103e-12]\n",
      " [1.86510139e-12 1.00000000e+00]\n",
      " [1.00000000e+00 7.37333805e-13]\n",
      " [1.00000000e+00 3.08085610e-12]\n",
      " [1.79355751e-24 1.00000000e+00]\n",
      " [1.00000000e+00 7.45320611e-11]\n",
      " [1.00000000e+00 2.47490177e-22]\n",
      " [1.00000000e+00 9.83462172e-20]\n",
      " [1.00000000e+00 7.66953792e-11]\n",
      " [1.00000000e+00 3.01159722e-11]\n",
      " [1.00000000e+00 2.44538956e-35]\n",
      " [1.00000000e+00 1.12330872e-32]\n",
      " [1.00000000e+00 8.64723397e-12]\n",
      " [4.45274562e-02 9.55472589e-01]\n",
      " [1.00000000e+00 2.75631925e-24]\n",
      " [1.00000000e+00 5.58698570e-15]\n",
      " [2.17167884e-09 1.00000000e+00]\n",
      " [1.00000000e+00 6.90877841e-11]\n",
      " [3.59180255e-11 1.00000000e+00]\n",
      " [9.99998569e-01 1.41836085e-06]\n",
      " [2.96878971e-29 1.00000000e+00]\n",
      " [1.00000000e+00 2.71691191e-16]\n",
      " [1.00000000e+00 2.41385889e-09]\n",
      " [1.00000000e+00 6.99146721e-23]\n",
      " [2.92934501e-03 9.97070670e-01]\n",
      " [7.10138821e-20 1.00000000e+00]\n",
      " [1.00000000e+00 9.01511252e-22]\n",
      " [1.13870649e-10 1.00000000e+00]\n",
      " [1.42560562e-12 1.00000000e+00]\n",
      " [1.00000000e+00 5.03882418e-14]\n",
      " [1.00000000e+00 1.51943991e-09]\n",
      " [4.42296745e-26 1.00000000e+00]\n",
      " [9.99999762e-01 2.19501757e-07]\n",
      " [1.00000000e+00 5.21830081e-08]\n",
      " [1.00000000e+00 1.54521586e-11]\n",
      " [4.39971948e-11 1.00000000e+00]\n",
      " [1.00000000e+00 2.04561576e-10]\n",
      " [1.00000000e+00 3.75818523e-08]\n",
      " [3.08875050e-13 1.00000000e+00]\n",
      " [9.99875188e-01 1.24748243e-04]\n",
      " [3.27584916e-04 9.99672413e-01]\n",
      " [9.14806902e-01 8.51931125e-02]\n",
      " [3.83917433e-29 1.00000000e+00]\n",
      " [3.96033329e-06 9.99996066e-01]\n",
      " [9.99999523e-01 4.72435175e-07]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.90790963e-01 9.20902193e-03]\n",
      " [9.99912262e-01 8.77653220e-05]\n",
      " [1.00000000e+00 1.09645555e-08]\n",
      " [9.99998331e-01 1.69275063e-06]\n",
      " [2.18728313e-10 1.00000000e+00]\n",
      " [1.20886392e-32 1.00000000e+00]\n",
      " [2.71219980e-09 1.00000000e+00]\n",
      " [1.00000000e+00 2.90212336e-27]\n",
      " [1.00000000e+00 5.71401643e-18]\n",
      " [1.00000000e+00 5.80068788e-15]\n",
      " [4.33300618e-10 1.00000000e+00]\n",
      " [2.92794811e-09 1.00000000e+00]\n",
      " [4.20839001e-07 9.99999523e-01]\n",
      " [9.99994993e-01 4.95011363e-06]\n",
      " [1.00000000e+00 1.04914273e-08]\n",
      " [2.77638564e-35 1.00000000e+00]\n",
      " [1.00000000e+00 2.53014101e-17]\n",
      " [8.00486621e-11 1.00000000e+00]\n",
      " [3.30066390e-20 1.00000000e+00]\n",
      " [1.00000000e+00 2.78274300e-12]\n",
      " [1.47317939e-33 1.00000000e+00]\n",
      " [1.00000000e+00 9.09494609e-28]\n",
      " [2.01009527e-07 9.99999762e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [4.20942725e-11 1.00000000e+00]\n",
      " [8.17622900e-01 1.82377130e-01]\n",
      " [4.69779126e-15 1.00000000e+00]\n",
      " [9.99876857e-01 1.23132588e-04]\n",
      " [1.00000000e+00 1.80751139e-12]\n",
      " [9.99757111e-01 2.42889175e-04]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [6.80831373e-01 3.19168568e-01]\n",
      " [3.96033693e-06 9.99996066e-01]\n",
      " [1.61671865e-04 9.99838352e-01]\n",
      " [9.99999881e-01 1.66616715e-07]\n",
      " [9.99963641e-01 3.64108346e-05]\n",
      " [8.01048672e-11 1.00000000e+00]\n",
      " [9.99997973e-01 2.00242994e-06]\n",
      " [9.94902611e-01 5.09733148e-03]\n",
      " [1.00000000e+00 1.63206571e-35]\n",
      " [2.06596129e-11 1.00000000e+00]\n",
      " [1.00683911e-17 1.00000000e+00]\n",
      " [2.70055689e-22 1.00000000e+00]\n",
      " [1.00000000e+00 1.82005238e-08]\n",
      " [9.99999881e-01 9.37513960e-08]\n",
      " [1.83334970e-21 1.00000000e+00]\n",
      " [1.40968359e-05 9.99985933e-01]\n",
      " [1.52954201e-12 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [9.99979734e-01 2.02949432e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(yhat_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes = []\n",
    "for i in range(len(yhat_probs)):\n",
    "    if(yhat_probs[i][0]<.5):\n",
    "        yhat_classes.append(0.)\n",
    "    else:\n",
    "        yhat_classes.append(1.)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat_classes = np.array(yhat_classes)\n",
    "# print(yhat_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_test_labels = []\n",
    "for i in range(len(test_labels)):\n",
    "    if(test_labels[i][0]==0):\n",
    "        single_test_labels.append(0.) \n",
    "    else:\n",
    "        single_test_labels.append(1.)\n",
    "single_test_labels= np.array(single_test_labels)        \n",
    "    \n",
    "# print(single_test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.944000\n",
      "Precision: 0.961686\n",
      "Recall: 0.933086\n",
      "F1 score: 0.947170\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(single_test_labels, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(single_test_labels, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(single_test_labels, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(single_test_labels, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lenovo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('cnn_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87.50784  12.492156]]\n"
     ]
    }
   ],
   "source": [
    "#prediction on real time data\n",
    "f1 = open('scraping/article.txt', \"r\")\n",
    "text = f1.read()\n",
    "#tokenize\n",
    "tok = tokenize_text([text])\n",
    "pred = model.predict(tok) # % real %fake\n",
    "print(pred*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using LSTMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(sequence_input, embedded_sequences, classes=2):\n",
    "    x = LSTM(32,return_sequences=True)(embedded_sequences)\n",
    "    x = LSTM(64,return_sequences=True)(x)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dense(4096,activation='relu')(x)\n",
    "    x = Dense(1024,activation='relu')(x)\n",
    "    preds = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5aff6b229c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msequence_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0membedded_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_SEQUENCE_LENGTH=1500\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "model = LSTM_model(sequence_input, embedded_sequences, classes=2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adamax',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
